{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Required Downloads\n",
    "\"\"\"\n",
    "    libraries down\n",
    "    facenet_keras model : https://drive.google.com/drive/folders/12aMYASGCKvDdkygSv1yQq8ns03AStDO_\n",
    "    haarcascade opencv classifier : https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define facedetector and model , both takes time\n",
    "model=tf.keras.models.load_model('facenet_keras.h5',compile=False)\n",
    "facedetector=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_student(directory,name):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(directory,name))\n",
    "    except OSError as error:\n",
    "        print('Student already exists')\n",
    "        return \n",
    "    \n",
    "    try:\n",
    "        cam=cv2.VideoCapture(0)\n",
    "        pic_count=-2\n",
    "        while pic_count<50:\n",
    "            ret,frame=cam.read()\n",
    "            if ret==0:\n",
    "                break \n",
    "            faces=facedetector.detectMultiScale(\n",
    "                image=frame,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=8\n",
    "            )\n",
    "            for (x,y,w,h) in faces:\n",
    "                pic_count+=1\n",
    "                if pic_count>0:\n",
    "                    cv2.imwrite(os.path.join(os.path.join(directory,name),str(pic_count)+'.jpg'),frame[y:y+h,x:x+w])\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "                \n",
    "            cv2.imshow('img',frame)\n",
    "            if cv2.waitKey(500)&0xff==ord('q'):\n",
    "                break\n",
    "    except:\n",
    "        print('Erro while capturing images')\n",
    "    finally:\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_students_encoding(model,directory):\n",
    "    students_encoding={}\n",
    "    list_of_students=os.listdir(directory)\n",
    "    for student in list_of_students:\n",
    "        images=[]\n",
    "        newdirectory=os.path.join(directory,student)\n",
    "        for pic in os.listdir(newdirectory):\n",
    "            image=cv2.imread(os.path.join(newdirectory,pic))\n",
    "            images.append(cv2.resize(image,(160,160),cv2.INTER_AREA)/255.0)\n",
    "        dataset=np.array(images)\n",
    "        encode=model.predict(dataset)\n",
    "        print(student,encode,encode.shape,encode[0][0])\n",
    "        students_encoding[student]=encode\n",
    "    \n",
    "    return students_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatedistance(encode1,encode2):\n",
    "    distance=tf.reduce_sum(tf.square(tf.subtract(encode1,encode2)))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_distance(test_encoding,list_of_encodings):\n",
    "    dist=1000\n",
    "    for encoding in list_of_encodings:\n",
    "        dist=min(dist,np.linalg.norm(test_encoding-encoding))\n",
    "        #dist=min(dist,calculatedistance(test_encoding,encoding))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_student(test_encoding,students_encoding,threshold):\n",
    "    dist=1000\n",
    "    id=\"unknown\"\n",
    "    \n",
    "    for name,encodings in students_encoding.items():\n",
    "        newdist=get_min_distance(test_encoding,encodings)\n",
    "        if newdist<dist:\n",
    "            dist=newdist\n",
    "            id=name\n",
    "    if dist>threshold:\n",
    "        id=\"unknown\"\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=r'facedatabase'\n",
    "threshold=8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import csv\n",
    "def take_attendance(directory,threshold,model):\n",
    "    # Face recognition (with liveness detection) code\n",
    "    # Generate and store the face encodings of known students using their face images.\n",
    "    # To be done using pre trained model( FaceNet) but here i used face_recognition python library .\n",
    "    # Images of students are stored in 'students_images' directory .\n",
    "    known_faces_encodings=get_students_encoding(model,directory)\n",
    "\n",
    "    try:\n",
    "        video=cv2.VideoCapture(0)\n",
    "        success=1\n",
    "\n",
    "        # OpenCV Haar-feature based cascade classifier for detecting eyes \n",
    "        eye_cascade=cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "        # load the model trained for predicting whether or not the eyes are closed\n",
    "        json_file=open(\"eye_model.json\",\"r\")\n",
    "        eye_model=tf.keras.models.model_from_json(json_file.read())\n",
    "        json_file.close()\n",
    "        eye_model.load_weights(\"eye_model.h5\")\n",
    "\n",
    "\n",
    "        # Dictionary with key representing the rollno of recognised student and value representing the status of eyes ( either open or closed )\n",
    "        recognised_students={}\n",
    "\n",
    "        while success:\n",
    "\n",
    "            sucess,frame=video.read()\n",
    "            print(frame.shape)\n",
    "            frame_gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            is_processed=0\n",
    "            if is_processed==0 :\n",
    "\n",
    "\n",
    "                #detected_faces_locations = fc.face_locations(frame)\n",
    "                detected_faces_locations=facedetector.detectMultiScale(frame,1.1,8)\n",
    "               # detected_faces_encodings = fc.face_encodings(frame,detected_faces_locations)\n",
    "\n",
    "                detected_faces_rollno=[]\n",
    "\n",
    "                # For each detected face in the frame generate its face encoding and compare it with encodings of known students.\n",
    "                # If matched append its rollno in an array or append 'unknown'\n",
    "                #for encoding in detected_faces_encodings:\n",
    "\n",
    "                #    rollno=identify_student(encoding,known_faces_encodings,threshold)\n",
    "\n",
    "                #    detected_faces_rollno.append(rollno)\n",
    "\n",
    "                for (x,y,w,h) in detected_faces_locations:\n",
    "                    croppedframe=frame[y:y+h,x:x+w]\n",
    "                    croppedframe=cv2.resize(croppedframe,(160,160),cv2.INTER_AREA)/255.0\n",
    "                    dataset=np.array([croppedframe])\n",
    "                    encoding_of_frame=model.predict(dataset)[0]\n",
    "                    rollno=identify_student(encoding_of_frame,known_faces_encodings,threshold)\n",
    "\n",
    "                    detected_faces_rollno.append(rollno)\n",
    "\n",
    "\n",
    "\n",
    "                #frame = cv2.putText(frame,id,(x,y),cv2.FONT_HERSHEY_SIMPLEX ,1,(255,255,255),1, cv2.LINE_AA)\n",
    "\n",
    "                # For each detected Face do \n",
    "                for (fx,fy,fw,fh),rollno in zip(detected_faces_locations,detected_faces_rollno):\n",
    "                    left=fx \n",
    "                    right=fx+fw\n",
    "                    top=fy\n",
    "                    bottom=fy+fh\n",
    "\n",
    "                    if rollno=='unknown':\n",
    "                        # if person is unknown do noting\n",
    "                        cv2.rectangle(frame,(left,top),(right,bottom),(0,0,255),2)\n",
    "                    else:\n",
    "                        # if student is known do liveness detection using blink detection\n",
    "                        cv2.rectangle(frame,(left,top),(right,bottom),(0,255,0),2)\n",
    "                        cv2.putText(frame,rollno,(left+6,bottom-6),cv2.FONT_HERSHEY_DUPLEX,1.0,(255,255,255),1)\n",
    "\n",
    "                        # detect eyes in the face\n",
    "                        roi_gray = frame_gray[top:bottom,left:right]\n",
    "                        eyes= eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "                        # If any one or both the eyes are open flag becomes 1\n",
    "                        flag=0\n",
    "                        for (ex,ey,ew,eh) in eyes:\n",
    "                            roi=frame[ey+top:ey+eh+top,ex+left:ex+left+ew]\n",
    "                            roi=cv2.resize(roi,(32,32),interpolation=cv2.INTER_AREA)\n",
    "                            roi=np.expand_dims(roi,axis=0)\n",
    "                            roi=np.reshape(roi,(1,32,32,3))\n",
    "                            image_to_classify=np.vstack([roi])\n",
    "\n",
    "                            classes=eye_model.predict(image_to_classify,batch_size=10)\n",
    "\n",
    "                            # If probab that eye is open is greater than 0.5 predict eye is open\n",
    "                            if classes[0][0]>=0.5 :\n",
    "                                flag=1\n",
    "                                \n",
    "                            cv2.rectangle(frame,(ex+left,ey+top),(ex+ew+left,ey+eh+top),(0,255,0),2)\n",
    "\n",
    "                        status='Closed'\n",
    "                        if flag==1:\n",
    "                            status='Open'\n",
    "\n",
    "                       \n",
    "                        cv2.putText(frame,status,(left+6,bottom+20),cv2.FONT_HERSHEY_DUPLEX,1.0,(0,0,255),1)\n",
    "\n",
    "                        # If eyes are closed now but previously it was observed to be open->Blink detected\n",
    "                        if status=='Closed':\n",
    "                            if rollno not in recognised_students:\n",
    "                                recognised_students.update({rollno:0})\n",
    "                            else:\n",
    "                                if recognised_students[rollno]==1:\n",
    "                                    #---------------------------------------\n",
    "                                    print('Present '+rollno+' '+str(time.ctime()))\n",
    "                                    now=datetime.datetime.now()\n",
    "                                    date_now=now.strftime(\"%Y-%m-%d\")\n",
    "                                    time_now=now.strftime(\"%H:%M:%S\")\n",
    "                                    attendance_today = 'Attendance/'+date_now+'.csv'\n",
    "                                    is_present=0 \n",
    "                                    try:\n",
    "                                        \n",
    "                                        if os.path.isfile(attendance_today)==False:\n",
    "                                            with open(attendance_today,\"w\",newline='') as csvfile :\n",
    "                                                writer=csv.writer(csvfile)\n",
    "                                                writer.writerow(['Rollno','Time'])\n",
    "\n",
    "                                        with open(attendance_today,\"r\") as csvfile:\n",
    "                                            reader=csv.reader(csvfile)\n",
    "                                            for row in reader:\n",
    "                                                if row[0]==rollno:\n",
    "                                                    is_present=1\n",
    "\n",
    "\n",
    "                                        if is_present==0:\n",
    "                                            with open(attendance_today,\"a+\") as csvfile:\n",
    "                                                writer=csv.writer(csvfile)\n",
    "                                                writer.writerow([rollno,time_now])\n",
    "                                    \n",
    "                                    except:\n",
    "                                        print('not able to write to file')\n",
    "                                    \n",
    "                                        \n",
    "                                    \n",
    "                                    \n",
    "                                    #---------------------------------------\n",
    "                                recognised_students[rollno]=0\n",
    "\n",
    "                        else:\n",
    "                            if rollno not in recognised_students:\n",
    "                                recognised_students.update({rollno:1})\n",
    "                            else:\n",
    "                                recognised_students[rollno]=1\n",
    "\n",
    "\n",
    "\n",
    "                cv2.imshow('Videos',frame)\n",
    "\n",
    "                if cv2.waitKey(1)&0xff==ord('q'):\n",
    "                    break\n",
    "                success=1\n",
    "                is_processed=1\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "    \n",
    "    except :\n",
    "        print('error')\n",
    "    finally:\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017UCO1681 [[-0.794441    0.5630461  -0.46722916 ... -1.5034713  -0.01064781\n",
      "  -0.14555463]\n",
      " [-0.29301408  0.99474037 -0.48575583 ... -1.1201731   0.08601064\n",
      "  -0.19399399]\n",
      " [-0.32805842 -0.28586274 -1.7698416  ... -1.5699167  -0.32414165\n",
      "  -0.7220616 ]\n",
      " ...\n",
      " [-0.6696851   0.18716687 -0.5117941  ... -1.3744818  -0.24771947\n",
      "  -0.4354531 ]\n",
      " [-0.60240364  0.30953375 -0.7762976  ... -1.6341368  -0.32724398\n",
      "  -0.4422367 ]\n",
      " [-0.6609287   0.19037566 -0.07958349 ... -1.9720551  -0.7974063\n",
      "  -0.6145537 ]] (50, 128) -0.794441\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "Present 2017UCO1681 Fri May  8 10:54:43 2020\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "Present 2017UCO1681 Fri May  8 10:54:44 2020\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "Present 2017UCO1681 Fri May  8 10:54:44 2020\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    take_attendance(directory,threshold,model)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
