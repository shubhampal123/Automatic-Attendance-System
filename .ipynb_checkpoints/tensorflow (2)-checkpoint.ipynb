{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Downloads\n",
    "\"\"\"\n",
    "    libraries down\n",
    "    facenet_keras model : https://drive.google.com/drive/folders/12aMYASGCKvDdkygSv1yQq8ns03AStDO_\n",
    "    haarcascade opencv classifier : https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define facedetector and model , both takes time\n",
    "model=tf.keras.models.load_model('facenet_keras.h5',compile=False)\n",
    "facedetector=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_student(directory,name):\n",
    "    try:\n",
    "        os.mkdir(os.path.join(directory,name))\n",
    "    except OSError as error:\n",
    "        print('Student already exists')\n",
    "        return \n",
    "    \n",
    "    try:\n",
    "        cam=cv2.VideoCapture(0)\n",
    "        pic_count=-2\n",
    "        while pic_count<50:\n",
    "            ret,frame=cam.read()\n",
    "            if ret==0:\n",
    "                break \n",
    "            faces=facedetector.detectMultiScale(\n",
    "                image=frame,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=8\n",
    "            )\n",
    "            for (x,y,w,h) in faces:\n",
    "                pic_count+=1\n",
    "                if pic_count>0:\n",
    "                    cv2.imwrite(os.path.join(os.path.join(directory,name),str(pic_count)+'.jpg'),frame[y:y+h,x:x+w])\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "                \n",
    "            cv2.imshow('img',frame)\n",
    "            if cv2.waitKey(500)&0xff==ord('q'):\n",
    "                break\n",
    "    except:\n",
    "        print('Erro while capturing images')\n",
    "    finally:\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_students_encoding(model,directory):\n",
    "    students_encoding={}\n",
    "    list_of_students=os.listdir(directory)\n",
    "    for student in list_of_students:\n",
    "        images=[]\n",
    "        newdirectory=os.path.join(directory,student)\n",
    "        for pic in os.listdir(newdirectory):\n",
    "            image=cv2.imread(os.path.join(newdirectory,pic))\n",
    "            images.append(cv2.resize(image,(160,160),cv2.INTER_AREA)/255.0)\n",
    "        dataset=np.array(images)\n",
    "        encode=model.predict(dataset)\n",
    "        students_encoding[student]=encode\n",
    "    \n",
    "    return students_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatedistance(encode1,encode2):\n",
    "    distance=tf.reduce_sum(tf.square(tf.subtract(encode1,encode2)))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_distance(test_encoding,list_of_encodings):\n",
    "    dist=1000\n",
    "    for encoding in list_of_encodings:\n",
    "        dist=min(dist,np.linalg.norm(test_encoding-encoding))\n",
    "        #dist=min(dist,calculatedistance(test_encoding,encoding))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_student(test_encoding,students_encoding,threshold):\n",
    "    dist=1000\n",
    "    id=\"unknown\"\n",
    "    \n",
    "    for name,encodings in students_encoding.items():\n",
    "        newdist=get_min_distance(test_encoding,encodings)\n",
    "        if newdist<dist:\n",
    "            dist=newdist\n",
    "            id=name\n",
    "    if dist>threshold:\n",
    "        id=\"unknown\"\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=r'facedatabase'\n",
    "threshold=8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-595a362a43ee>, line 146)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-595a362a43ee>\"\u001b[0;36m, line \u001b[0;32m146\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import csv\n",
    "def take_attendance(directory,threshold,model):\n",
    "    # Face recognition (with liveness detection) code\n",
    "    # Generate and store the face encodings of known students using their face images.\n",
    "    # To be done using pre trained model( FaceNet) but here i used face_recognition python library .\n",
    "    # Images of students are stored in 'students_images' directory .\n",
    "    known_faces_encodings=get_students_encoding(model,directory)\n",
    "\n",
    "    try:\n",
    "        video=cv2.VideoCapture(0)\n",
    "        success=1\n",
    "\n",
    "        # OpenCV Haar-feature based cascade classifier for detecting eyes \n",
    "        eye_cascade=cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "        # load the model trained for predicting whether or not the eyes are closed\n",
    "        json_file=open(\"eye_model.json\",\"r\")\n",
    "        eye_model=tf.keras.models.model_from_json(json_file.read())\n",
    "        json_file.close()\n",
    "        eye_model.load_weights(\"eye_model.h5\")\n",
    "\n",
    "\n",
    "        # Dictionary with key representing the rollno of recognised student and value representing the status of eyes ( either open or closed )\n",
    "        recognised_students={}\n",
    "\n",
    "        while success:\n",
    "\n",
    "            sucess,frame=video.read()\n",
    "            frame_gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            is_processed=0\n",
    "            if is_processed==0 :\n",
    "\n",
    "\n",
    "                #detected_faces_locations = fc.face_locations(frame)\n",
    "                detected_faces_locations=facedetector.detectMultiScale(frame,1.1,8)\n",
    "               # detected_faces_encodings = fc.face_encodings(frame,detected_faces_locations)\n",
    "\n",
    "                detected_faces_rollno=[]\n",
    "\n",
    "                # For each detected face in the frame generate its face encoding and compare it with encodings of known students.\n",
    "                # If matched append its rollno in an array or append 'unknown'\n",
    "                #for encoding in detected_faces_encodings:\n",
    "\n",
    "                #    rollno=identify_student(encoding,known_faces_encodings,threshold)\n",
    "\n",
    "                #    detected_faces_rollno.append(rollno)\n",
    "\n",
    "                for (x,y,w,h) in detected_faces_locations:\n",
    "                    croppedframe=frame[y:y+h,x:x+w]\n",
    "                    croppedframe=cv2.resize(croppedframe,(160,160),cv2.INTER_AREA)/255.0\n",
    "                    dataset=np.array([croppedframe])\n",
    "                    encoding_of_frame=model.predict(dataset)[0]\n",
    "                    rollno=identify_student(encoding_of_frame,known_faces_encodings,threshold)\n",
    "\n",
    "                    detected_faces_rollno.append(rollno)\n",
    "\n",
    "\n",
    "\n",
    "                #frame = cv2.putText(frame,id,(x,y),cv2.FONT_HERSHEY_SIMPLEX ,1,(255,255,255),1, cv2.LINE_AA)\n",
    "\n",
    "                # For each detected Face do \n",
    "                for (fx,fy,fw,fh),rollno in zip(detected_faces_locations,detected_faces_rollno):\n",
    "                    left=fx \n",
    "                    right=fx+fw\n",
    "                    top=fy\n",
    "                    bottom=fy+fh\n",
    "\n",
    "                    if rollno=='unknown':\n",
    "                        # if person is unknown do noting\n",
    "                        cv2.rectangle(frame,(left,top),(right,bottom),(0,0,255),2)\n",
    "                    else:\n",
    "                        # if student is known do liveness detection using blink detection\n",
    "                        cv2.rectangle(frame,(left,top),(right,bottom),(0,255,0),2)\n",
    "                        cv2.putText(frame,rollno,(left+6,bottom-6),cv2.FONT_HERSHEY_DUPLEX,1.0,(255,255,255),1)\n",
    "\n",
    "                        # detect eyes in the face\n",
    "                        roi_gray = frame_gray[top:bottom,left:right]\n",
    "                        eyes= eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "                        # If any one or both the eyes are open flag becomes 1\n",
    "                        flag=0\n",
    "                        for (ex,ey,ew,eh) in eyes:\n",
    "                            roi=frame[ey+top:ey+eh+top,ex+left:ex+left+ew]\n",
    "                            roi=cv2.resize(roi,(32,32),interpolation=cv2.INTER_AREA)\n",
    "                            roi=np.expand_dims(roi,axis=0)\n",
    "                            roi=np.reshape(roi,(1,32,32,3))\n",
    "                            image_to_classify=np.vstack([roi])\n",
    "\n",
    "                            classes=eye_model.predict(image_to_classify,batch_size=10)\n",
    "\n",
    "                            # If probab that eye is open is greater than 0.5 predict eye is open\n",
    "                            if classes[0][0]>=0.5 :\n",
    "                                flag=1\n",
    "                                \n",
    "                            cv2.rectangle(frame,(ex+left,ey+top),(ex+ew+left,ey+eh+top),(0,255,0),2)\n",
    "\n",
    "                        status='Closed'\n",
    "                        if flag==1:\n",
    "                            status='Open'\n",
    "\n",
    "                       \n",
    "                        cv2.putText(frame,status,(left+6,bottom+20),cv2.FONT_HERSHEY_DUPLEX,1.0,(0,0,255),1)\n",
    "\n",
    "                        # If eyes are closed now but previously it was observed to be open->Blink detected\n",
    "                        if status=='Closed':\n",
    "                            if rollno not in recognised_students:\n",
    "                                recognised_students.update({rollno:0})\n",
    "                            else:\n",
    "                                if recognised_students[rollno]==1:\n",
    "                                    #---------------------------------------\n",
    "                                    print('Present '+rollno+' '+str(time.ctime()))\n",
    "                                    now=datetime.datetime.now()\n",
    "                                    date_now=now.strftime(\"%Y-%m-%d\")\n",
    "                                    time_now=now.strftime(\"%H:%M:%S\")\n",
    "                                    attendance_today = 'Attendance/'+date_now+'.csv'\n",
    "                                    is_present=0 \n",
    "                                    try:\n",
    "                                        \n",
    "                                        if os.path.isfile(attendance_today)==False:\n",
    "                                            with open(attendance_today,\"w\",newline='') as csvfile :\n",
    "                                                writer=csv.writer(csvfile)\n",
    "                                                writer.writerow(['Rollno','Time'])\n",
    "\n",
    "                                        with open(attendance_today,\"r\") as csvfile:\n",
    "                                            reader=csv.reader(csvfile)\n",
    "                                            for row in reader:\n",
    "                                                if row[0]==rollno:\n",
    "                                                    is_present=1\n",
    "\n",
    "\n",
    "                                        if is_present==0:\n",
    "                                            with open(attendance_today,\"a+\") as csvfile:\n",
    "                                                writer=csv.writer(csvfile)\n",
    "                                                writer.writerow([rollno,time_now])\n",
    "                                    \n",
    "                                    except:\n",
    "                                        print('not able to write to file')\n",
    "                                    \n",
    "                                        \n",
    "                                    \n",
    "                                    \n",
    "                                    #---------------------------------------\n",
    "                                recognised_students[rollno]=0\n",
    "\n",
    "                        else:\n",
    "                            if rollno not in recognised_students:\n",
    "                                recognised_students.update({rollno:1})\n",
    "                            else:\n",
    "                                recognised_students[rollno]=1\n",
    "\n",
    "\n",
    "\n",
    "                cv2.imshow('Videos',frame)\n",
    "\n",
    "                if cv2.waitKey(1)&0xff==ord('q'):\n",
    "                    break\n",
    "                success=1\n",
    "                is_processed=1\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "    \n",
    "    except :\n",
    "        print('error')\n",
    "    finally:\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present 2017UCO1681 Mon Apr 13 15:18:54 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:18:57 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:18:59 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:02 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:02 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:02 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:03 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:04 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:10 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:22 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:24 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:25 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:28 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:29 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:30 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:31 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:34 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:35 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:36 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:40 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:49 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:51 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:52 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:59 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:19:59 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:02 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:05 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:07 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:07 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:09 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:11 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:13 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:14 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:17 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:18 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:20 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:20 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:21 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:24 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:25 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:27 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:33 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:35 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:37 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:40 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:40 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:41 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:42 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:42 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:43 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:43 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:44 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:45 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:46 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:46 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:47 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:47 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:49 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:51 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:54 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:55 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:56 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:58 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:20:59 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:01 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:01 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:02 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:02 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:03 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:04 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:05 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:05 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:06 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:06 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:08 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:08 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:09 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:10 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:11 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:12 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:12 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:14 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:16 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:18 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:21 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:22 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:29 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:35 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:36 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:38 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:40 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:40 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:41 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:41 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:42 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:47 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:48 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:57 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:21:58 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:00 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:02 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:04 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:04 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:08 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:08 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:10 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:13 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:15 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:16 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:17 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:17 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:18 2020\n",
      "Present 2017UCO1681 Mon Apr 13 15:22:19 2020\n"
     ]
    }
   ],
   "source": [
    "take_attendance(directory,threshold,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_student(directory,\"2017UCO1681\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
